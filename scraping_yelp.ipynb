{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Recommendation By Review\n",
    "- Scrape and analyze review data from NYC\n",
    "- Using NLP techniques, identify common features of highly-reviewed establishments to generate recommendations by training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import requests\n",
    "import nest_asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_web_scrape(iterable, individual_scrape_function, *args):\n",
    "    \"\"\"\n",
    "    This function does something analogous to compiling the get_data_asynchronously function,\n",
    "    Then it executes loop.\n",
    "    1. Call the get_data_function\n",
    "    2. Get the event_loop\n",
    "    3. Run the tasks (Much easier to understand in python 3.7, \"ensure_future\" was changed to \"create_task\")\n",
    "    4. Edge_list and top_interactions will be passed to the next functions\n",
    "    \"\"\"\n",
    "    nest_asyncio.apply()\n",
    "    async def create_scrape_loop(iterable, individual_scrape_function, *args):\n",
    "        \"\"\"\n",
    "        1. Establish an executor and number of workers\n",
    "        2. Establish the session\n",
    "        3. Establish the event loop\n",
    "        4. Create the task by list comprenhensions\n",
    "        5. Gather tasks.\n",
    "        \"\"\"\n",
    "        with ThreadPoolExecutor(max_workers=40) as executor:\n",
    "            with requests.Session() as session:\n",
    "                loop = asyncio.get_event_loop()\n",
    "                tasks = [\n",
    "                    loop.run_in_executor(\n",
    "                        executor, individual_scrape_function, *(i, *args)\n",
    "                    )\n",
    "                    for i in iterable\n",
    "                ]\n",
    "                for response in await asyncio.gather(*tasks):\n",
    "                    pass\n",
    "    \n",
    "    future = asyncio.ensure_future(\n",
    "        create_scrape_loop(iterable, individual_scrape_function,*args)\n",
    "    )\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_biz_url(url):\n",
    "    if (\"?hrid\" in url)|(\"/adredir?ad_business_id\" in url)|( \"/search?cflt\" in url)|(\"yelp.com/city/nyc\" in url)|(\"databyacxiom\" in url):\n",
    "        pass\n",
    "    else:\n",
    "        return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_yelp_search(start_number, business_type, location, all_links):\n",
    "#     url = 'https://www.yelp.com/search?cflt='+business_type+'&find_loc='+location+'&start='\n",
    "    url = \"https://www.yelp.com/search?cflt=coffee&find_loc=New%20York%2C%20NY&start=\"\n",
    "    r = requests.get(url+str(start_number)).text\n",
    "    soup = BeautifulSoup(r, \"html.parser\")\n",
    "    a = soup.find_all(\"a\",{\"class\":\"lemon--a__373c0__IEZFH link__373c0__29943 link-color--blue-dark__373c0__1mhJo link-size--inherit__373c0__2JXk5\"})\n",
    "    links = [filter_biz_url(i[\"href\"]) for i in a if filter_biz_url(i[\"href\"]) is not None]\n",
    "    all_links.extend(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_yelp_search(start_number, all_links):\n",
    "#     url = 'https://www.yelp.com/search?cflt='+business_type+'&find_loc='+location+'&start='\n",
    "    url = \"https://www.yelp.com/search?cflt=coffee&find_loc=New%20York%2C%20NY&start=\"\n",
    "    r = requests.get(url+str(start_number)).text\n",
    "    soup = BeautifulSoup(r, \"html.parser\")\n",
    "    a = soup.find_all(\"a\",{\"class\":\"lemon--a__373c0__IEZFH link__373c0__29943 link-color--blue-dark__373c0__1mhJo link-size--inherit__373c0__2JXk5\"})\n",
    "    links = [filter_biz_url(i[\"href\"]) for i in a if filter_biz_url(i[\"href\"]) is not None]\n",
    "    all_links.extend(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_type = 'coffee' # business type: painter, autorepair, burger\n",
    "location = \"New York, NY\" # city, state\n",
    "location = location.replace(\" \", \"%20\").replace(\",\", \"%2C\")\n",
    "# yelp shows 30 per page, so increments of 30 for starting number = 0\n",
    "all_links = []\n",
    "async_web_scrape(list(range(0,1200,30)), scrape_yelp_search, all_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/biz/kaffe-1668-south-new-york',\n",
       " '/biz/harbs-new-york-13',\n",
       " '/biz/outpost-caf%C3%A9-brooklyn-3',\n",
       " '/biz/la-colombe-coffee-new-york-5',\n",
       " '/biz/marcy-and-myrtle-cafe-bedford-stuyvesant',\n",
       " '/biz/swallow-cafe-cobble-hill',\n",
       " '/biz/cranberrys-brooklyn',\n",
       " '/biz/yanni-s-coffee-new-york',\n",
       " '/biz/mud-new-york-3',\n",
       " '/biz/joe-coffee-company-brooklyn-2']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_ny_ny_list = all_links\n",
    "len(coffee_ny_ny_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "def scraper(biz_url, review_index=20):\n",
    "    \n",
    "    # get url\n",
    "    yelp_url = \"https://www.yelp.com\" \n",
    "    review_url = \"/review_feed?sort_by=date_desc&start=\"\n",
    "    full_url = yelp_url + biz_url + review_url + str(review_index)\n",
    "\n",
    "    colnames = ['date', 'review', 'star_rating']\n",
    "    df_reviews = pd.DataFrame(columns=colnames)\n",
    "    with requests.get(full_url, timeout=20) as response: \n",
    "        if response.status_code==200:\n",
    "            string = response.json()\n",
    "            div = html.fromstring(string['review_list'])\n",
    "            reviews = [e.text for e in div.xpath(\"//div[@class='review-content']/p\")]\n",
    "            dates = div.xpath(\"//div[@class='review-content']/descendant::span[@class='rating-qualifier']/text()\")\n",
    "            star_ratings = div.xpath(\"//div[@class='review-content']/descendant::div[@class='biz-rating__stars']/div/@title\")\n",
    "            df = pd.DataFrame([dates, reviews, star_ratings]).T\n",
    "            df.columns = colnames\n",
    "            df['date'] = df['date'].apply(lambda x: x.strip())\n",
    "#             df['star_rating'] = df['star_rating'].apply(lambda x: float(x[:3]))\n",
    "            df_reviews = pd.concat([df_reviews, df], ignore_index=True)\n",
    "            del df\n",
    "   \n",
    "    return df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scraper(coffee_ny_ny_list[1], 20)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for y in range(len(coffee_ny_ny_list)):\n",
    "    for x in range(0,1000,20):\n",
    "        df = scraper(coffee_ny_ny_list[y], x)\n",
    "        df_list.append(df)\n",
    "coffee_ny_ny = pd.concat(df_list, join='outer', axis=0, ignore_index=True)\n",
    "coffee_ny_ny['star_rating'] = coffee_ny_ny['star_rating'].apply(lambda x: float(x[:3]))\n",
    "coffee_ny_ny['keyword'] = 'coffee'\n",
    "coffee_ny_ny = coffee_ny_ny.dropna()\n",
    "print(coffee_ny_ny.shape)\n",
    "coffee_ny_ny.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2042"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_ny_ny.to_csv('coffee_ny_ny_yelp_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "def yelp_review_scraper(biz_id, starting_review_index=0):\n",
    "    \n",
    "    # get url\n",
    "    yelp_url = \"https://www.yelp.com\" \n",
    "    yelp_review = \"/review_feed?sort_by=date_desc&start=\"\n",
    "    full_url = yelp_url + biz_id + yelp_review + str(starting_review_index)\n",
    "\n",
    "    cols = ['date', 'review', 'star_rating']\n",
    "    yelp_reviews = pd.DataFrame(columns=cols)\n",
    "    with requests.get(full_url, timeout=20) as response: \n",
    "        if response.status_code==200:\n",
    "            json_text = response.json()\n",
    "            div = html.fromstring(json_text['review_list'])\n",
    "            reviews = [e.text for e in div.xpath(\"//div[@class='review-content']/p\")]\n",
    "            dates = div.xpath(\"//div[@class='review-content']/descendant::span[@class='rating-qualifier']/text()\")\n",
    "            star_ratings = div.xpath(\"//div[@class='review-content']/descendant::div[@class='biz-rating__stars']/div/@title\")\n",
    "            star_ratings = float(star_ratings[:3])\n",
    "            df = pd.DataFrame([dates, reviews, star_ratings]).T\n",
    "            df.columns = cols\n",
    "            df['date'] = df['date'].apply(lambda x: x.strip())\n",
    "            yelp_reviews = pd.concat([yelp_reviews, df], ignore_index=True)\n",
    "            del df\n",
    "   \n",
    "    return yelp_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for x in range(0,500,20):\n",
    "    df = yelp_review_scraper(coffee_ny_ny_list[0], x)\n",
    "    df_list.append(df)\n",
    "coffee_ny_ny = pd.concat(df_list, join='outer', axis=0, ignore_index=True)\n",
    "coffee_ny_ny = coffee_ny_ny.dropna()\n",
    "print(coffee_ny_ny.shape)\n",
    "coffee_ny_ny.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
